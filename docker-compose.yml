version: '3.8'
services:
  llm-app:
    container_name: llm-RAG
    build:
      context: .
      dockerfile: Dockerfile
      # target: builder   # optional: if you used multi-stage and want a specific stage
    restart: unless-stopped
    env_file:
      - .env
    ports:
      - '3000:3000'
    command: npm run start:dev
    volumes:
      - ./:/app # Mount project into container so watcher sees changes
      - /app/node_modules # keep container's node_modules (prevents host overwrite)
    healthcheck:
      test: ['CMD-SHELL', 'curl -f http://localhost:3000/health || exit 1']
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 5s
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    restart: unless-stopped
    ports:
      - '9090:9090'
    volumes:
      # We are injecting our own config (prometheus.yml) into the container.
      # Without this, Prometheus would run with its default config, and not scrape your llm-app.
      # If we edit prometheus.yml locally, changes will be reflected inside the container (after restart).
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    depends_on:
      - llm-app

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    restart: unless-stopped
    ports:
      - '3001:3000'
    depends_on:
      - prometheus
